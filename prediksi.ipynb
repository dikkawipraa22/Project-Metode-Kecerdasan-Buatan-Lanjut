{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>aktivasi</th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "      <th>mse</th>\n",
       "      <th>bobot</th>\n",
       "      <th>bias</th>\n",
       "      <th>bobot_output</th>\n",
       "      <th>bias_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>[[[np.float64(0.10699418429729088), np.float64...</td>\n",
       "      <td>[[0.572809207821098, np.float64(-0.01365306829...</td>\n",
       "      <td>[np.float64(0.6234574260724818), np.float64(0....</td>\n",
       "      <td>0.059012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>[[[np.float64(-0.13980825343409117), np.float6...</td>\n",
       "      <td>[[0.27418607228555925, np.float64(-0.440165911...</td>\n",
       "      <td>[np.float64(0.8626237422754499), np.float64(0....</td>\n",
       "      <td>0.803570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>[[[np.float64(-0.3377971785796175), np.float64...</td>\n",
       "      <td>[[0.7100748314478269, np.float64(-0.7321976046...</td>\n",
       "      <td>[np.float64(0.5310673728570456), np.float64(0....</td>\n",
       "      <td>0.331533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>[[[np.float64(0.40518274425828454), np.float64...</td>\n",
       "      <td>[[0.3153681780340243, np.float64(-0.4282997955...</td>\n",
       "      <td>[np.float64(0.18454241556813414), np.float64(0...</td>\n",
       "      <td>0.652523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>[[[np.float64(-3.7256119299037502), np.float64...</td>\n",
       "      <td>[[0.6035591159166552, np.float64(-2.0137836647...</td>\n",
       "      <td>[np.float64(0.7919511051997543), np.float64(0....</td>\n",
       "      <td>0.439488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>[[[np.float64(0.2826365466464155), np.float64(...</td>\n",
       "      <td>[[0.9113737427963798, 0.973856609016062, 0.637...</td>\n",
       "      <td>[np.float64(0.9915155316629379), np.float64(0....</td>\n",
       "      <td>0.537151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>[[[np.float64(0.1985110682361901), np.float64(...</td>\n",
       "      <td>[[0.7774285706745424, 0.7164500242489753, 0.79...</td>\n",
       "      <td>[np.float64(0.5044970953156604), np.float64(0....</td>\n",
       "      <td>0.845093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>200</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>[[[np.float64(-0.008355418518446327), np.float...</td>\n",
       "      <td>[[0.4309213539541634, 0.6873961104254199, 0.42...</td>\n",
       "      <td>[np.float64(0.1577739035273022), np.float64(0....</td>\n",
       "      <td>0.769307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>[[[np.float64(0.4972485929988115), np.float64(...</td>\n",
       "      <td>[[0.5810752836706177, 0.3503533507632055, 0.46...</td>\n",
       "      <td>[np.float64(0.2463835693924553), np.float64(0....</td>\n",
       "      <td>0.456962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>[[[np.float64(-0.13968315274239895), np.float6...</td>\n",
       "      <td>[[0.3673813428792523, 0.07355465282264373, 0.8...</td>\n",
       "      <td>[np.float64(0.6872369578017116), np.float64(0....</td>\n",
       "      <td>0.856283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hidden_layer hidden_neuron aktivasi       lr  epoch       mse  \\\n",
       "0               1          (2,)     relu  0.00001    100  0.003616   \n",
       "1               1          (2,)     relu  0.00001    200  0.021683   \n",
       "2               1          (2,)     relu  0.00010    100  0.006859   \n",
       "3               1          (2,)     relu  0.00010    200  0.010269   \n",
       "4               1          (2,)     relu  0.00100    100  0.081554   \n",
       "..            ...           ...      ...      ...    ...       ...   \n",
       "283             2        (4, 4)     tanh  0.00001    200  0.083203   \n",
       "284             2        (4, 4)     tanh  0.00010    100  0.013800   \n",
       "285             2        (4, 4)     tanh  0.00010    200  0.012734   \n",
       "286             2        (4, 4)     tanh  0.00100    100  0.014646   \n",
       "287             2        (4, 4)     tanh  0.00100    200  0.012946   \n",
       "\n",
       "                                                 bobot  \\\n",
       "0    [[[np.float64(0.10699418429729088), np.float64...   \n",
       "1    [[[np.float64(-0.13980825343409117), np.float6...   \n",
       "2    [[[np.float64(-0.3377971785796175), np.float64...   \n",
       "3    [[[np.float64(0.40518274425828454), np.float64...   \n",
       "4    [[[np.float64(-3.7256119299037502), np.float64...   \n",
       "..                                                 ...   \n",
       "283  [[[np.float64(0.2826365466464155), np.float64(...   \n",
       "284  [[[np.float64(0.1985110682361901), np.float64(...   \n",
       "285  [[[np.float64(-0.008355418518446327), np.float...   \n",
       "286  [[[np.float64(0.4972485929988115), np.float64(...   \n",
       "287  [[[np.float64(-0.13968315274239895), np.float6...   \n",
       "\n",
       "                                                  bias  \\\n",
       "0    [[0.572809207821098, np.float64(-0.01365306829...   \n",
       "1    [[0.27418607228555925, np.float64(-0.440165911...   \n",
       "2    [[0.7100748314478269, np.float64(-0.7321976046...   \n",
       "3    [[0.3153681780340243, np.float64(-0.4282997955...   \n",
       "4    [[0.6035591159166552, np.float64(-2.0137836647...   \n",
       "..                                                 ...   \n",
       "283  [[0.9113737427963798, 0.973856609016062, 0.637...   \n",
       "284  [[0.7774285706745424, 0.7164500242489753, 0.79...   \n",
       "285  [[0.4309213539541634, 0.6873961104254199, 0.42...   \n",
       "286  [[0.5810752836706177, 0.3503533507632055, 0.46...   \n",
       "287  [[0.3673813428792523, 0.07355465282264373, 0.8...   \n",
       "\n",
       "                                          bobot_output  bias_output  \n",
       "0    [np.float64(0.6234574260724818), np.float64(0....     0.059012  \n",
       "1    [np.float64(0.8626237422754499), np.float64(0....     0.803570  \n",
       "2    [np.float64(0.5310673728570456), np.float64(0....     0.331533  \n",
       "3    [np.float64(0.18454241556813414), np.float64(0...     0.652523  \n",
       "4    [np.float64(0.7919511051997543), np.float64(0....     0.439488  \n",
       "..                                                 ...          ...  \n",
       "283  [np.float64(0.9915155316629379), np.float64(0....     0.537151  \n",
       "284  [np.float64(0.5044970953156604), np.float64(0....     0.845093  \n",
       "285  [np.float64(0.1577739035273022), np.float64(0....     0.769307  \n",
       "286  [np.float64(0.2463835693924553), np.float64(0....     0.456962  \n",
       "287  [np.float64(0.6872369578017116), np.float64(0....     0.856283  \n",
       "\n",
       "[288 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning = pd.read_csv('hasiltuning.csv')\n",
    "tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fungsi aktivasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aktivasiX(activ, x): \n",
    "    # aktivasi relu\n",
    "    if activ == 'relu':\n",
    "        if x >= 0:\n",
    "            return x\n",
    "        else:\n",
    "            return 0\n",
    "    # aktivasi sigmoid\n",
    "    elif activ == 'sigmoid':\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    # aktivasi softmax\n",
    "    elif activ == 'softmax':\n",
    "        return 1\n",
    "    # aktivasi tanh\n",
    "    else:\n",
    "        return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
    "\n",
    "def turunanaktivasiX(activ, x): \n",
    "    # turunan aktivasi relu\n",
    "    if activ == 'relu':\n",
    "        if x > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # turunan aktivasi sigmoid\n",
    "    elif activ == 'sigmoid':\n",
    "        sig = 1 / (1 + math.exp(-x))\n",
    "        return sig * (1 - sig)\n",
    "    # turunan aktivasi softmax\n",
    "    elif activ == 'softmax':\n",
    "        return 0\n",
    "    # turunan aktivasi tanh\n",
    "    else:\n",
    "        tan = (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
    "        return 1 - (tan) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Index: 28\n",
      "Best Hidden Layer: 1\n",
      "Best Hidden Neuron: (3,)\n",
      "Best Aktivasi: relu\n",
      "Best Learning Rate: 0.001\n",
      "Best Epoch: 100\n",
      "Best MSE: 0.0007618043596218\n",
      "Best Bobot: [[[np.float64(-3.506497907825722), np.float64(1.9697768314244195), np.float64(-0.9240204427783485)], [np.float64(-2.7306406184200447), np.float64(1.9873068834011653), np.float64(-1.2322599781989798)], [np.float64(-3.310959958354285), np.float64(2.495941077204169), np.float64(-0.8517473837460467)], [np.float64(-0.9355686898103772), np.float64(1.4043908560731893), np.float64(0.30766327915648356)]]]\n",
      "Best Bias: [[0.5263830414299532, 0.9340327119824176, np.float64(-1.8809548645363972)]]\n",
      "Best Bobot Output: [np.float64(0.8210520159429506), np.float64(0.10923785583848392), np.float64(0.3123763203010679)]\n",
      "Best Bias Output: 0.118527835944195\n"
     ]
    }
   ],
   "source": [
    "best_index = tuning['mse'].idxmin()\n",
    "best_hidden_layer_global = tuning['hidden_layer'][best_index]\n",
    "best_hidden_neuron_global = tuning['hidden_neuron'][best_index]\n",
    "best_aktivasi_global = tuning['aktivasi'][best_index]\n",
    "best_lr_global = tuning['lr'][best_index]\n",
    "best_epoch_global = tuning['epoch'][best_index]\n",
    "best_mse_global = tuning['mse'][best_index]\n",
    "best_bobot_global = tuning['bobot'][best_index]\n",
    "best_bias_global = tuning['bias'][best_index]\n",
    "best_bobot_output_global = tuning['bobot_output'][best_index]\n",
    "best_bias_output_global = tuning['bias_output'][best_index]\n",
    "\n",
    "print(\"Best Index:\", best_index)\n",
    "print(\"Best Hidden Layer:\", best_hidden_layer_global)\n",
    "print(\"Best Hidden Neuron:\", best_hidden_neuron_global)\n",
    "print(\"Best Aktivasi:\", best_aktivasi_global)\n",
    "print(\"Best Learning Rate:\", best_lr_global)\n",
    "print(\"Best Epoch:\", best_epoch_global)\n",
    "print(\"Best MSE:\", best_mse_global)\n",
    "print(\"Best Bobot:\", best_bobot_global)\n",
    "print(\"Best Bias:\", best_bias_global)\n",
    "print(\"Best Bobot Output:\", best_bobot_output_global)\n",
    "print(\"Best Bias Output:\", best_bias_output_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mengembalikan menjadi list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bobot_global = eval(best_bobot_global)\n",
    "best_bias_global = eval(best_bias_global)\n",
    "best_bobot_output_global = eval(best_bobot_output_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediksi Data Baru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fungsi prediksi data baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_new, bobot, bias, bobot_output, bias_output, aktivasi):\n",
    "    prediksi = []\n",
    "    for i in range(len(X_new)):\n",
    "        # FEEDFORWARD\n",
    "        # Operasi pada Hidden Layer\n",
    "        aktivasi_hidden = []\n",
    "        for j in range(len(bobot)):  # untuk setiap hidden layer\n",
    "            aktivasi_hidden_temp = []\n",
    "            for k in range(len(bobot[j][0])):  # jumlah neuron di hidden layer\n",
    "                sumXbobot = 0\n",
    "                if j == 0:  # layer pertama\n",
    "                    for l in range(4):  # jumlah neuron input\n",
    "                        sumXbobot += bobot[j][l][k] * X_new[i][l]\n",
    "                else:\n",
    "                    for l in range(len(aktivasi_hidden[j - 1])):\n",
    "                        sumXbobot += bobot[j][l][k] * aktivasi_hidden[j - 1][l]\n",
    "                sumXbobotbias = bias[j][k] + sumXbobot\n",
    "                aktivasi_hidden_temp.append(aktivasiX(aktivasi, sumXbobotbias))\n",
    "            aktivasi_hidden.append(aktivasi_hidden_temp)\n",
    "\n",
    "        # Operasi pada Output Layer\n",
    "        sumZbobotoutput = 0\n",
    "        for j in range(len(aktivasi_hidden[-1])):\n",
    "            sumZbobotoutput += bobot_output[j] * aktivasi_hidden[-1][j]\n",
    "        sumZbobotoutput_biasoutput = bias_output + sumZbobotoutput\n",
    "        predik = aktivasiX(aktivasi, sumZbobotoutput_biasoutput)\n",
    "        prediksi.append(predik)\n",
    "\n",
    "    return prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contoh prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angka Harapan Hidup     : 65.655\n",
      "Rerata Lama Sekolah     : 9.76\n",
      "Harapan Lama Sekolah    : 14.28\n",
      "Pengeluaran Per Kapita  : 7686\n",
      "------------------------------------------\n",
      "HASIL PREDIKSI          : 70.26310531865263\n",
      "KATEGORI IPM            : Tinggi\n"
     ]
    }
   ],
   "source": [
    "# angka_harapan_hidup, rerata_lama_sekolah, harapan_lama_sekolah, pengeluaran_per_kapita\n",
    "X_new = [[65.655, 9.76, 14.28, 7686]]\n",
    "\n",
    "scaler_fitur = joblib.load('model scaling/fitur_mmscaler_model.pkl')\n",
    "X_new_scaled = scaler_fitur.transform(X_new)\n",
    "\n",
    "hasil_prediksi = predict(X_new_scaled, best_bobot_global, best_bias_global, best_bobot_output_global, best_bias_output_global, best_aktivasi_global)\n",
    "\n",
    "scaler_target = joblib.load('model scaling/target_mmscaler_y.pkl')\n",
    "y_pred_original = scaler_target.inverse_transform([[hasil_prediksi[0]]])\n",
    "\n",
    "# pengkategorian IPM\n",
    "if y_pred_original[0][0] >= 80:\n",
    "    kategori = 'Sangat Tinggi'\n",
    "elif 70 <= y_pred_original[0][0] < 80:\n",
    "    kategori = 'Tinggi'\n",
    "elif 60 <= y_pred_original[0][0] < 70:\n",
    "    kategori = 'Sedang'\n",
    "else:\n",
    "    kategori = 'Rendah'\n",
    "\n",
    "print(f\"Angka Harapan Hidup     : {X_new[0][0]}\")\n",
    "print(f\"Rerata Lama Sekolah     : {X_new[0][1]}\")\n",
    "print(f\"Harapan Lama Sekolah    : {X_new[0][2]}\")\n",
    "print(f\"Pengeluaran Per Kapita  : {X_new[0][3]}\")\n",
    "print(\"------------------------------------------\")\n",
    "print(f\"HASIL PREDIKSI          : {y_pred_original[0][0]}\")\n",
    "print(f\"KATEGORI IPM            : {kategori}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
